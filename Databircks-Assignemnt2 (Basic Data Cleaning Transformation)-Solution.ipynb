{"cells":[{"cell_type":"markdown","source":["<span style=\"color:orange\">\n <h2> Databircks-Assignemnt 2 (Basic Data Cleaning Transformation)\n</span>\n  <h5>\n    <span style=\"color:red\">\n<b>Author: Deepak Goyal <br>\n   <a> adeus.azurelib.com </a><br>\n   Email at: admin@azurelib.com\n</span>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"df7e83ba-34cd-4f9e-8fb5-eb5ec719cf28","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<b> Find the count of duplicate employee records in the input file (based on id)?"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"62c53c84-5d19-4115-a775-314575ce42fc","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Write your code using the Spark Function\nfrom pyspark.sql.functions import *\ndf = spark.read.csv(\"dbfs:/FileStore/EmployeeData_yMCQAbYLYU.csv\", header=True, inferSchema=True)\n#aggregate functions ignores NULL values\ndf1 = df.groupBy(df.id).agg(count(df.id).alias('cnt'))\ndf1.filter(df1.cnt > 1).show()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2d4e6162-dd1d-497a-b403-121b7b3ad8da","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+---+\n| id|cnt|\n+---+---+\n+---+---+\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["<b> Find out how many records have Gender value missing."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"8364e840-c519-4ac5-a1bf-b9b89b994321","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Write your code using the Spark Function\ndf2 = df.filter('gender is null').count()\ndisplay(df2)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a0185598-138a-4fd1-a503-3e1a0c301712","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/plain":["28"]}}],"execution_count":0},{"cell_type":"markdown","source":["d\n<b> Are there any missing values in the \"bonus\" field? If so, filled them defualt bonus 100."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"14772c70-beff-49d9-828a-724188863639","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Write your code using the Spark Function\n## Transformation always takes new memory space\ndf2 = df.withColumn('bonus_updated', when(col('bonus').isNull(),100).otherwise(col('bonus')))\ndf2.drop('bonus').withColumnRenamed('bonus_updated','bonus').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"5233f351-ed0d-4c5d-8c49-b382053a6e91","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+----------+---------+--------------------+------+------+-------------------+--------+\n| id|first_name|last_name|               email|gender|salary|       creationDate|   bonus|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\n|  1|    Valene|   Ingley|vingley0@livejour...|Female| 44104|1957-09-09 16:44:40|   100.0|\n|  2|  Lynnelle|    Hurll| lhurll1@answers.com|Female|112411|1907-05-10 17:38:56|   100.0|\n|  3|   Miranda|    Train|   mtrain2@imgur.com|Female| 91073|1941-01-24 16:05:23|12875.54|\n|  4|    Dulsea|     Foss|dfoss3@dagondesig...|Female|193291|1942-05-09 20:59:39|   100.0|\n|  5|    Anatol|  Dunklee| adunklee4@google.de|  Male| 22175|1950-07-26 16:28:00| 1432.12|\n|  6|     Baily|   Antony| bantony5@sfgate.com|  Male|127337|1913-10-14 11:25:33|   100.0|\n|  7|    Eunice|   Cardus|ecardus6@scientif...|Female|136574|1901-11-02 15:09:47|38676.94|\n|  8|  Aubrette|  Lippett| alippett7@nifty.com|Female|165713|1919-12-16 08:20:42|60150.66|\n|  9|   Sibylla|Sickamore|ssickamore8@faceb...|Female|107243|2020-03-15 15:00:30|   100.0|\n| 10|      null|   Altree|paltree9@dropbox.com|Female|197594|1975-06-21 23:27:12|72533.37|\n| 11|      Coop|    Richt|   crichta@sogou.com|  Male| 19964|1939-02-13 16:18:24|56973.41|\n| 12|  Giuseppe|  Scimoni|gscimonib@craigsl...|  Male|176531|1967-04-06 07:23:03|   100.0|\n| 13|    Lovell|  Iorizzo|liorizzoc@cpanel.net|  Male|189150|1949-06-06 16:25:20| 41474.8|\n| 14|       Deb|    Mogra|   dmograd@bbc.co.uk|Female|197829|1997-07-27 14:55:52|46528.57|\n| 15|  Hastings| Jelliman|hjellimane@histat...|  Male|179296|1915-07-05 07:02:06|80194.64|\n| 16|     Josee|   Burnep|    jburnepf@php.net|  null| 78569|1923-11-08 20:59:14|88925.13|\n| 17|     Gilly|   Fownes|gfownesg@redcross...|Female|  2527|1946-07-30 21:10:57|   100.0|\n| 18|      null|Schruyers|lschruyersh@desde...|  Male|109936|1979-06-16 01:12:48|37243.09|\n| 19|     Maris|Chatelain| mchatelaini@unc.edu|Female|190047|2008-01-11 17:16:21|76469.65|\n| 20|    Casper|  Aughtie|    caughtiej@vk.com|  Male| 38689|1982-04-06 05:13:49| 80404.8|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["d\n<b> Are there any employees with negative salary or bonus amounts in the input file? If so, how many?"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"cae0fe03-6339-4dac-9a18-1a5a1da78612","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Write your code using the Spark Function\ndf.filter((df.salary < 0) | (df.bonus < 0)).count()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"0bf0728d-c9ff-4d5f-9cb4-00d7a34bb988","inputWidgets":{},"title":""}},"outputs":[{"output_type":"execute_result","metadata":{},"execution_count":35,"output_type":"execute_result","data":{"text/plain":["0"]}}],"execution_count":0},{"cell_type":"markdown","source":["d\n<b> Replace all the null/emtpy value in email column with admin@azurelib.com"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"8e58642b-6aff-4351-92a0-cea48bfdc948","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Write your code using the Spark Function\ndf.fillna(\"admin@azurelib.com\",['email']).show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4288320d-f41e-4719-99a6-93fe790beacb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+----------+---------+--------------------+------+------+-------------------+--------+\n| id|first_name|last_name|               email|gender|salary|       creationDate|   bonus|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\n|  1|    Valene|   Ingley|vingley0@livejour...|Female| 44104|1957-09-09 16:44:40|    null|\n|  2|  Lynnelle|    Hurll| lhurll1@answers.com|Female|112411|1907-05-10 17:38:56|    null|\n|  3|   Miranda|    Train|   mtrain2@imgur.com|Female| 91073|1941-01-24 16:05:23|12875.54|\n|  4|    Dulsea|     Foss|dfoss3@dagondesig...|Female|193291|1942-05-09 20:59:39|    null|\n|  5|    Anatol|  Dunklee| adunklee4@google.de|  Male| 22175|1950-07-26 16:28:00| 1432.12|\n|  6|     Baily|   Antony| bantony5@sfgate.com|  Male|127337|1913-10-14 11:25:33|    null|\n|  7|    Eunice|   Cardus|ecardus6@scientif...|Female|136574|1901-11-02 15:09:47|38676.94|\n|  8|  Aubrette|  Lippett| alippett7@nifty.com|Female|165713|1919-12-16 08:20:42|60150.66|\n|  9|   Sibylla|Sickamore|ssickamore8@faceb...|Female|107243|2020-03-15 15:00:30|    null|\n| 10|      null|   Altree|paltree9@dropbox.com|Female|197594|1975-06-21 23:27:12|72533.37|\n| 11|      Coop|    Richt|   crichta@sogou.com|  Male| 19964|1939-02-13 16:18:24|56973.41|\n| 12|  Giuseppe|  Scimoni|gscimonib@craigsl...|  Male|176531|1967-04-06 07:23:03|    null|\n| 13|    Lovell|  Iorizzo|liorizzoc@cpanel.net|  Male|189150|1949-06-06 16:25:20| 41474.8|\n| 14|       Deb|    Mogra|   dmograd@bbc.co.uk|Female|197829|1997-07-27 14:55:52|46528.57|\n| 15|  Hastings| Jelliman|hjellimane@histat...|  Male|179296|1915-07-05 07:02:06|80194.64|\n| 16|     Josee|   Burnep|    jburnepf@php.net|  null| 78569|1923-11-08 20:59:14|88925.13|\n| 17|     Gilly|   Fownes|gfownesg@redcross...|Female|  2527|1946-07-30 21:10:57|    null|\n| 18|      null|Schruyers|lschruyersh@desde...|  Male|109936|1979-06-16 01:12:48|37243.09|\n| 19|     Maris|Chatelain| mchatelaini@unc.edu|Female|190047|2008-01-11 17:16:21|76469.65|\n| 20|    Casper|  Aughtie|    caughtiej@vk.com|  Male| 38689|1982-04-06 05:13:49| 80404.8|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["d\n<b> Remove all the records where any record has any null values. Find out the total count of the records now."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d39815e9-f12a-497e-a658-fc9f1c98d271","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Write your code using the Spark Function\n##function to be inclosed in ()\ndf.dropna().show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c1035982-814b-43ff-b9df-55e89c658f68","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+----------+-----------+--------------------+------+------+-------------------+--------+\n| id|first_name|  last_name|               email|gender|salary|       creationDate|   bonus|\n+---+----------+-----------+--------------------+------+------+-------------------+--------+\n|  3|   Miranda|      Train|   mtrain2@imgur.com|Female| 91073|1941-01-24 16:05:23|12875.54|\n|  5|    Anatol|    Dunklee| adunklee4@google.de|  Male| 22175|1950-07-26 16:28:00| 1432.12|\n|  7|    Eunice|     Cardus|ecardus6@scientif...|Female|136574|1901-11-02 15:09:47|38676.94|\n|  8|  Aubrette|    Lippett| alippett7@nifty.com|Female|165713|1919-12-16 08:20:42|60150.66|\n| 11|      Coop|      Richt|   crichta@sogou.com|  Male| 19964|1939-02-13 16:18:24|56973.41|\n| 13|    Lovell|    Iorizzo|liorizzoc@cpanel.net|  Male|189150|1949-06-06 16:25:20| 41474.8|\n| 14|       Deb|      Mogra|   dmograd@bbc.co.uk|Female|197829|1997-07-27 14:55:52|46528.57|\n| 15|  Hastings|   Jelliman|hjellimane@histat...|  Male|179296|1915-07-05 07:02:06|80194.64|\n| 19|     Maris|  Chatelain| mchatelaini@unc.edu|Female|190047|2008-01-11 17:16:21|76469.65|\n| 20|    Casper|    Aughtie|    caughtiej@vk.com|  Male| 38689|1982-04-06 05:13:49| 80404.8|\n| 22|     Becki|      Conry|bconryl@examiner.com|Female| 10203|2003-02-07 10:00:05|47067.23|\n| 23|      Edie|      Orniz|eornizm@moonfruit...|Female| 81920|1982-10-03 14:48:25|20019.85|\n| 24|   Sharity|     Fronks|sfronksn@economis...|Female|169527|1951-06-14 19:32:49| 4960.71|\n| 25|     Vally|   Dahlberg|vdahlbergo@dyndns...|Female| 80628|1924-07-07 06:20:37|60914.52|\n| 26|     Effie|Maffioletti|emaffiolettip@pos...|Female| 34228|1986-03-23 12:03:27|31496.73|\n| 31|    Blayne|  Yuranovev|byuranovevu@blogt...|  Male|188551|1998-07-27 11:30:51|27111.81|\n| 32|      Maud|     Formby|mformbyv@macromed...|Female|182359|1964-08-24 11:02:47|77984.03|\n| 37|    Maggee|     Rablin|mrablin10@mashabl...|Female|134344|2004-10-08 01:50:46|60163.15|\n| 38|     Nikki|    Woolner|nwoolner11@linked...|Female|  3792|1942-05-13 12:11:21|21054.48|\n| 40|    Farlee|    Fincken|ffincken13@google...|  Male|126873|1937-06-14 23:34:30|58907.18|\n+---+----------+-----------+--------------------+------+------+-------------------+--------+\nonly showing top 20 rows\n\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Databircks-Assignemnt2 (Basic Data Cleaning Transformation)-L8vhi321Hx","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":592839168542518}},"nbformat":4,"nbformat_minor":0}
